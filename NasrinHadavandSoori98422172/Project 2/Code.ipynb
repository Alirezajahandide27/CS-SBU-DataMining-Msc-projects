{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>302.00000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.42053</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.963576</td>\n",
       "      <td>131.602649</td>\n",
       "      <td>246.500000</td>\n",
       "      <td>0.149007</td>\n",
       "      <td>0.526490</td>\n",
       "      <td>149.569536</td>\n",
       "      <td>0.327815</td>\n",
       "      <td>1.043046</td>\n",
       "      <td>1.397351</td>\n",
       "      <td>0.718543</td>\n",
       "      <td>2.314570</td>\n",
       "      <td>0.543046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.04797</td>\n",
       "      <td>0.466426</td>\n",
       "      <td>1.032044</td>\n",
       "      <td>17.563394</td>\n",
       "      <td>51.753489</td>\n",
       "      <td>0.356686</td>\n",
       "      <td>0.526027</td>\n",
       "      <td>22.903527</td>\n",
       "      <td>0.470196</td>\n",
       "      <td>1.161452</td>\n",
       "      <td>0.616274</td>\n",
       "      <td>1.006748</td>\n",
       "      <td>0.613026</td>\n",
       "      <td>0.498970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.50000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  302.00000  302.000000  302.000000  302.000000  302.000000  302.000000   \n",
       "mean    54.42053    0.682119    0.963576  131.602649  246.500000    0.149007   \n",
       "std      9.04797    0.466426    1.032044   17.563394   51.753489    0.356686   \n",
       "min     29.00000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.00000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.50000    1.000000    1.000000  130.000000  240.500000    0.000000   \n",
       "75%     61.00000    1.000000    2.000000  140.000000  274.750000    0.000000   \n",
       "max     77.00000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  302.000000  302.000000  302.000000  302.000000  302.000000  302.000000   \n",
       "mean     0.526490  149.569536    0.327815    1.043046    1.397351    0.718543   \n",
       "std      0.526027   22.903527    0.470196    1.161452    0.616274    1.006748   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.250000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  152.500000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  302.000000  302.000000  \n",
       "mean     2.314570    0.543046  \n",
       "std      0.613026    0.498970  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data = pd.read_csv('heart(1).csv')\n",
    "data = data.replace(\"\",np.nan)\n",
    "data = data.dropna()\n",
    "data = data.drop_duplicates().reset_index(drop=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1th question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.abs(stats.zscore(data))\n",
    "rows = np.where((z > 3) | (z < -3))[0].tolist()\n",
    "\n",
    "data = data.drop(rows)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['target'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2th question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229, 13) (58, 13) (229,) (58,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['target'],axis=1),\n",
    "                                                    data['target'], test_size=0.2, shuffle=True)\n",
    "print(X_train.shape , X_test.shape , y_train.shape , y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "data2 = data[['chol','trestbps','thalach']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data2,\n",
    "                                                    data['target'], test_size=0.2, shuffle=True)\n",
    "\n",
    "class gaussClf:\n",
    "    def separate_by_classes(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        classes_index = {}\n",
    "        subdatasets = {}\n",
    "        cls, counts = np.unique(y, return_counts=True)\n",
    "        self.class_freq = dict(zip(cls, counts))\n",
    "        print(self.class_freq)\n",
    "        for class_type in self.classes:\n",
    "            classes_index[class_type] = np.argwhere(y==class_type)\n",
    "            subdatasets[class_type] = X[classes_index[class_type], :]\n",
    "            self.class_freq[class_type] = self.class_freq[class_type]/sum(list(self.class_freq.values()))\n",
    "        return subdatasets\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        separated_X = self.separate_by_classes(X, y)\n",
    "        self.means = {}\n",
    "        self.std = {}\n",
    "        for class_type in self.classes:\n",
    "            self.means[class_type] = np.mean(separated_X[class_type], axis=0)[0]\n",
    "            self.std[class_type] = np.std(separated_X[class_type], axis=0)[0]\n",
    "        \n",
    "    def calculate_probability(self, x, mean, stdev):\n",
    "        exponent = math.exp(-((x - mean) ** 2 / (2 * stdev ** 2)))\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.class_prob = {cls:math.log(self.class_freq[cls], math.e) for cls in self.classes}\n",
    "        for cls in self.classes:\n",
    "            for i in range(len(self.means)):\n",
    "                self.class_prob[cls]+=math.log(self.calculate_probability(X[i], self.means[cls][i], self.std[cls][i]), math.e)\n",
    "        self.class_prob = {cls: math.e**self.class_prob[cls] for cls in self.class_prob}\n",
    "        return self.class_prob\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = []\n",
    "        for x in X:\n",
    "            pred_class = None\n",
    "            max_prob = 0\n",
    "            for cls, prob in self.predict_proba(x).items():\n",
    "                if prob>max_prob:\n",
    "                    max_prob = prob\n",
    "                    pred_class = cls\n",
    "            pred.append(pred_class)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 98, 1: 131}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.10      0.17        31\n",
      "           1       0.48      0.96      0.64        27\n",
      "\n",
      "    accuracy                           0.50        58\n",
      "   macro avg       0.62      0.53      0.41        58\n",
      "weighted avg       0.62      0.50      0.39        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = gaussClf()\n",
    "clf.fit(X_train.values,y_train.values)\n",
    "print(classification_report(y_test.values,clf.predict(X_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6th question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.61      0.69        31\n",
      "           1       0.65      0.81      0.72        27\n",
      "\n",
      "    accuracy                           0.71        58\n",
      "   macro avg       0.72      0.71      0.71        58\n",
      "weighted avg       0.72      0.71      0.71        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train.values,y_train.values)\n",
    "print(classification_report(y_test.values,clf.predict(X_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8th question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.58      0.68        31\n",
      "           1       0.64      0.85      0.73        27\n",
      "\n",
      "    accuracy                           0.71        58\n",
      "   macro avg       0.73      0.72      0.70        58\n",
      "weighted avg       0.73      0.71      0.70        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train.values,y_train.values)\n",
    "print(classification_report(y_test.values,clf.predict(X_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9th question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.65      0.71        31\n",
      "           1       0.67      0.81      0.73        27\n",
      "\n",
      "    accuracy                           0.72        58\n",
      "   macro avg       0.73      0.73      0.72        58\n",
      "weighted avg       0.74      0.72      0.72        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel = 'linear')\n",
    "clf.fit(X_train.values,y_train.values)\n",
    "print(classification_report(y_test.values,clf.predict(X_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.61      0.68        31\n",
      "           1       0.64      0.78      0.70        27\n",
      "\n",
      "    accuracy                           0.69        58\n",
      "   macro avg       0.70      0.70      0.69        58\n",
      "weighted avg       0.70      0.69      0.69        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel = 'poly')\n",
    "clf.fit(X_train.values,y_train.values)\n",
    "print(classification_report(y_test.values,clf.predict(X_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10th question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86        32\n",
      "           1       0.78      0.96      0.86        26\n",
      "\n",
      "    accuracy                           0.86        58\n",
      "   macro avg       0.87      0.87      0.86        58\n",
      "weighted avg       0.88      0.86      0.86        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['target'],axis=1),\n",
    "                                                    data['target'], test_size=0.2, shuffle=True)\n",
    "\n",
    "clf = SVC(kernel = 'linear')\n",
    "clf.fit(X_train.values,y_train.values)\n",
    "print(classification_report(y_test.values,clf.predict(X_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11th question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score: 0.8380676328502416\n",
      "score std: 0.04456023563792447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\n",
    "print(f\"mean score: {scores.mean()}\")\n",
    "print(f\"score std: {scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12th question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.50      0.59        32\n",
      "           1       0.56      0.77      0.65        26\n",
      "\n",
      "    accuracy                           0.62        58\n",
      "   macro avg       0.64      0.63      0.62        58\n",
      "weighted avg       0.65      0.62      0.62        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print(classification_report(y_test.values,clf.predict(X_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14th question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.83      0.66        23\n",
      "           1       0.83      0.54      0.66        35\n",
      "\n",
      "    accuracy                           0.66        58\n",
      "   macro avg       0.68      0.68      0.66        58\n",
      "weighted avg       0.71      0.66      0.66        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2 = data[['chol','trestbps','thalach']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data2,\n",
    "                                                    data['target'], test_size=0.2, shuffle=True,random_state=42)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print(classification_report(y_test.values,clf.predict(X_test.values)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
