{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "correct-density",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:05:20.034738Z",
     "iopub.status.busy": "2021-04-06T12:05:20.034367Z",
     "iopub.status.idle": "2021-04-06T12:05:20.040994Z",
     "shell.execute_reply": "2021-04-06T12:05:20.040003Z",
     "shell.execute_reply.started": "2021-04-06T12:05:20.034704Z"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://sbu.ac.ir/documents/46019/275501/logo-dark.png\" alt=\"sbu\" class=\"center\">\n",
    "</center>\n",
    "\n",
    "\n",
    "# <center>Data Mining Course - Project #3</center>\n",
    "<center>\n",
    "    <b>Professors:</b>\n",
    "    <br>\n",
    "Dr. Farahani, Dr. Kheradpishe\n",
    "    <br><br><br>\n",
    "Ali Nikkhah - 99422197\n",
    "    <br><br>\n",
    "May 2021\n",
    "    <br><br>\n",
    "</center>\n",
    "\n",
    "\n",
    "# 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-packing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T15:25:58.312013Z",
     "iopub.status.busy": "2021-05-24T15:25:58.311050Z",
     "iopub.status.idle": "2021-05-24T15:25:58.325532Z",
     "shell.execute_reply": "2021-05-24T15:25:58.323908Z",
     "shell.execute_reply.started": "2021-05-24T15:25:58.311928Z"
    }
   },
   "source": [
    "<div style=\"direction:rtl; font-family:Vazir;font-size:16px;\">\n",
    " \n",
    "الگوریتم های SVM از مجموعه ای از توابع ریاضی که به عنوان کرنل تعریف می شوند، استفاده می کنند. وظیفه کرنل این است که داده ها را به عنوان ورودی گرفته و آن ها را به شکل مورد نیاز تبدیل کند. الگوریتم های مختلف SVM ، از انواع مختلف توابع کرنل استفاده می کنند. این توابع می توانند انواع متفاوتی داشته باشند. به عنوان مثال خطی ، غیرخطی ، چند جمله ای ، تابع پایه شعاعی (RBF) و سیگموئید.\n",
    "<br></br>\n",
    "توابع کرنل ، برای داده های ترتیبی ، نمودار ها ، متن ها ، تصاویر و همچنین بردار ها معرفی می شوند. پرکاربردترین نوع تابع کرنل، RBF است. زیرا دارای پاسخ محلی و متناهی در کل بازه محور x است.\n",
    " اما از لحاظ محاسباتی، محاسبه همه فیچر های اضافه مخصوصا در ترینینگ ست های بزرگ، هزینه زیادی دارد.\n",
    "<br></br>\n",
    "توابع کرنل ، ضرب داخلی بین دو نقطه در یک فضای ویژگی مناسب را برمی گردانند. بنابراین ، با هزینه محاسباتی کم، حتی در فضاهای با ابعاد بالا، مفهومی از شباهت را تعریف می کنند.\n",
    "<br></br>\n",
    "<b>کرنل چند جمله ای</b>\n",
    "<br></br>\n",
    "این کرنل در پردازش تصویر پرکاربرد است. معادله آن به صورت زیر است :\n",
    "<br>\n",
    "$$k(x_i,x_j)=(x_i\\cdot x_j+1)^d$$\n",
    "<br></br>\n",
    "که در آن d درجه چند جمله ای است.\n",
    "<br></br>\n",
    "<b>کرنل گاوسی</b>\n",
    "<br></br>\n",
    "این کرنل برای اهداف عمومی است. و هنگامی که هیچ دانش پیشینی در مورد داده ها وجود ندارد استفاده می شود. معادله آن به صورت زیر است :\n",
    "<br></br>\n",
    "$$k(x,y)=exp(-\\frac{\\left \\| x-y \\right \\|^{2}}{2\\sigma ^{2}})$$\n",
    "<br></br>\n",
    "<b>تابع پایه شعاعی گاوسی (RBF)</b>\n",
    "<br></br>\n",
    "این کرنل برای اهداف عمومی کاربرد دارد. و هنگامی که هیچ دانش پیشینی در مورد داده ها وجود نداشته باشد، مورد استفاده قرار می گیرد. معادله آن به صورت زیر است :\n",
    "<br></br>\n",
    "$$k(x_i,x_j)=exp(-\\gamma \\left \\| x_i - x_j \\right \\|^{2})$$\n",
    "<br></br>\n",
    "و برای\n",
    "<br>\n",
    "$$\\gamma > 0$$\n",
    "<br>\n",
    "گاهی اوقات با استفاده از پارامتر زیر استفاده می شود :\n",
    "<br></br>\n",
    "$$\\gamma = \\frac{1}{2\\sigma ^{2}}$$\n",
    "<br></br>\n",
    "<b>کرنل RBF لاپلاس</b>\n",
    "<br></br>\n",
    "این هم یک کرنل برای اهداف عمومی است. و هنگامی که هیچ دانش پیشینی در مورد داده ها وجود ندارد استفاده می شود. معادله آن به صورت زیر است :\n",
    "<br></br>\n",
    "$$k(x,y)=exp(-\\frac{\\left \\| x-y \\right \\|}{\\sigma })$$\n",
    "<br></br>\n",
    "<b>کرنل سیگموئید</b>\n",
    "<br></br>\n",
    "می توان این کرنل را در شبکه های عصبی مورد استفاده قرار داد. معادله مربوط به آن عبارت است از :\n",
    "<br></br>\n",
    "$$k(x,y)=\\tanh(\\alpha x^{T}y+c)$$\n",
    "<br></br>\n",
    "<b>کرنل spline خطی بصورت یک بعدی</b>\n",
    "<br></br>\n",
    "این کرنل، هنگام کار با بردارهای بزرگ داده پراکنده ، کاربرد زیادی دارد. این کرنل اغلب در دسته بندی متن مورد استفاده قرار می گیرد. کرنل spline همچنین در مسائل رگرسیون عملکرد خوبی دارد. معادله آن عبارت است از :\n",
    "<br></br>\n",
    "$$k(x,y)=1+xy+xy \\ min(x,y) -\\frac{x+y}{2} \\ min(x,y)^{2} + \\frac{1}{3} \\ min(x,y)^{3}$$\n",
    "<br></br>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-blake",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial-perth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T16:55:08.827172Z",
     "iopub.status.busy": "2021-05-24T16:55:08.826880Z",
     "iopub.status.idle": "2021-05-24T16:55:09.224439Z",
     "shell.execute_reply": "2021-05-24T16:55:09.223708Z",
     "shell.execute_reply.started": "2021-05-24T16:55:08.827139Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "welsh-resident",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T16:55:09.225986Z",
     "iopub.status.busy": "2021-05-24T16:55:09.225600Z",
     "iopub.status.idle": "2021-05-24T16:55:09.281326Z",
     "shell.execute_reply": "2021-05-24T16:55:09.280678Z",
     "shell.execute_reply.started": "2021-05-24T16:55:09.225962Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 21)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1859</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1004</td>\n",
       "      <td>1654</td>\n",
       "      <td>1067</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1821</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>381</td>\n",
       "      <td>1018</td>\n",
       "      <td>3220</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1954</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.8</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>1149</td>\n",
       "      <td>700</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1445</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>836</td>\n",
       "      <td>1099</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1137</td>\n",
       "      <td>1224</td>\n",
       "      <td>513</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "5           1859     0          0.5         1   3       0          22    0.7   \n",
       "6           1821     0          1.7         0   4       1          10    0.8   \n",
       "7           1954     0          0.5         1   0       0          24    0.8   \n",
       "8           1445     1          0.5         0   0       0          53    0.7   \n",
       "9            509     1          0.6         1   2       1           9    0.1   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "5        164        1  ...       1004      1654  1067    17     1         10   \n",
       "6        139        8  ...        381      1018  3220    13     8         18   \n",
       "7        187        4  ...        512      1149   700    16     3          5   \n",
       "8        174        7  ...        386       836  1099    17     1         20   \n",
       "9         93        5  ...       1137      1224   513    19    10         12   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "5        1             0     0            1  \n",
       "6        1             0     1            3  \n",
       "7        1             1     1            0  \n",
       "8        1             0     0            0  \n",
       "9        1             0     0            0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_test = pd.read_csv(\"test.csv\")\n",
    "mobile_train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "display(mobile_train.shape)\n",
    "mobile_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "piano-right",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T16:55:09.282376Z",
     "iopub.status.busy": "2021-05-24T16:55:09.282194Z",
     "iopub.status.idle": "2021-05-24T16:55:09.296197Z",
     "shell.execute_reply": "2021-05-24T16:55:09.295576Z",
     "shell.execute_reply.started": "2021-05-24T16:55:09.282359Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   int64  \n",
      " 1   blue           2000 non-null   int64  \n",
      " 2   clock_speed    2000 non-null   float64\n",
      " 3   dual_sim       2000 non-null   int64  \n",
      " 4   fc             2000 non-null   int64  \n",
      " 5   four_g         2000 non-null   int64  \n",
      " 6   int_memory     2000 non-null   int64  \n",
      " 7   m_dep          2000 non-null   float64\n",
      " 8   mobile_wt      2000 non-null   int64  \n",
      " 9   n_cores        2000 non-null   int64  \n",
      " 10  pc             2000 non-null   int64  \n",
      " 11  px_height      2000 non-null   int64  \n",
      " 12  px_width       2000 non-null   int64  \n",
      " 13  ram            2000 non-null   int64  \n",
      " 14  sc_h           2000 non-null   int64  \n",
      " 15  sc_w           2000 non-null   int64  \n",
      " 16  talk_time      2000 non-null   int64  \n",
      " 17  three_g        2000 non-null   int64  \n",
      " 18  touch_screen   2000 non-null   int64  \n",
      " 19  wifi           2000 non-null   int64  \n",
      " 20  price_range    2000 non-null   int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 328.2 KB\n"
     ]
    }
   ],
   "source": [
    "mobile_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spiritual-performer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T16:55:09.677887Z",
     "iopub.status.busy": "2021-05-24T16:55:09.677025Z",
     "iopub.status.idle": "2021-05-24T16:55:09.929417Z",
     "shell.execute_reply": "2021-05-24T16:55:09.928851Z",
     "shell.execute_reply.started": "2021-05-24T16:55:09.677808Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  83.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        92\n",
      "           1       0.77      0.78      0.77        96\n",
      "           2       0.74      0.81      0.77       106\n",
      "           3       0.97      0.83      0.89       106\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y = mobile_train[\"price_range\"].values\n",
    "x_data=mobile_train.drop([\"price_range\"],axis=1)\n",
    "x = (x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data))\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state=1)\n",
    "\n",
    "svc=SVC(random_state=1)\n",
    "svc.fit(x_train,y_train)\n",
    "svc_pred = svc.predict(x_test)\n",
    "svc_acc_score = accuracy_score(y_test, svc_pred)\n",
    "accuracy = accuracy_score(y_test, svc_pred)\n",
    "\n",
    "print(\"Accuracy : \", accuracy * 100)\n",
    "print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-dominican",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T18:33:11.092579Z",
     "iopub.status.busy": "2021-04-09T18:33:11.092375Z",
     "iopub.status.idle": "2021-04-09T18:33:11.095592Z",
     "shell.execute_reply": "2021-04-09T18:33:11.094889Z",
     "shell.execute_reply.started": "2021-04-09T18:33:11.092562Z"
    }
   },
   "source": [
    "# 3 & 4.\n",
    "\n",
    "C > 0 : soft margin\n",
    "<br>\n",
    "more larger C => more harder margin\n",
    "\n",
    "gamma: Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-negative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acknowledged-exclusion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:01:13.302913Z",
     "iopub.status.busy": "2021-05-24T17:01:13.302750Z",
     "iopub.status.idle": "2021-05-24T17:01:20.905021Z",
     "shell.execute_reply": "2021-05-24T17:01:20.904237Z",
     "shell.execute_reply.started": "2021-05-24T17:01:13.302897Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 1\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        92\n",
      "           1       0.82      0.89      0.85        96\n",
      "           2       0.79      0.84      0.81       106\n",
      "           3       0.98      0.83      0.90       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.1\n",
      "Accuracy :  90.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        92\n",
      "           1       0.86      0.91      0.88        96\n",
      "           2       0.85      0.89      0.87       106\n",
      "           3       0.98      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.1\n",
      "Accuracy :  91.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        92\n",
      "           1       0.87      0.90      0.88        96\n",
      "           2       0.89      0.90      0.89       106\n",
      "           3       0.97      0.92      0.94       106\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.1\n",
      "Accuracy :  92.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        92\n",
      "           1       0.89      0.88      0.88        96\n",
      "           2       0.90      0.92      0.91       106\n",
      "           3       0.98      0.92      0.95       106\n",
      "\n",
      "    accuracy                           0.92       400\n",
      "   macro avg       0.92      0.92      0.92       400\n",
      "weighted avg       0.92      0.92      0.92       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.1\n",
      "Accuracy :  90.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        92\n",
      "           1       0.88      0.89      0.88        96\n",
      "           2       0.85      0.89      0.87       106\n",
      "           3       0.95      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.1\n",
      "Accuracy :  90.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        92\n",
      "           1       0.88      0.89      0.88        96\n",
      "           2       0.83      0.90      0.86       106\n",
      "           3       0.96      0.89      0.92       106\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.91      0.90      0.90       400\n",
      "weighted avg       0.91      0.90      0.90       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.1\n",
      "Accuracy :  89.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        92\n",
      "           1       0.86      0.86      0.86        96\n",
      "           2       0.83      0.91      0.86       106\n",
      "           3       0.96      0.89      0.92       106\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.90      0.90      0.90       400\n",
      "weighted avg       0.90      0.90      0.90       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.1\n",
      "Accuracy :  89.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        92\n",
      "           1       0.86      0.85      0.86        96\n",
      "           2       0.82      0.91      0.86       106\n",
      "           3       0.96      0.89      0.92       106\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.90      0.89      0.89       400\n",
      "weighted avg       0.90      0.89      0.89       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.5\n",
      "Accuracy :  79.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        92\n",
      "           1       0.69      0.77      0.73        96\n",
      "           2       0.70      0.73      0.71       106\n",
      "           3       0.93      0.80      0.86       106\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.80      0.80      0.80       400\n",
      "weighted avg       0.80      0.80      0.80       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91        92\n",
      "           1       0.76      0.81      0.79        96\n",
      "           2       0.76      0.80      0.78       106\n",
      "           3       0.94      0.84      0.89       106\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.80      0.77        96\n",
      "           2       0.75      0.79      0.77       106\n",
      "           3       0.94      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.76      0.78      0.77       106\n",
      "           3       0.93      0.86      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.83      0.84       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        92\n",
      "           1       0.82      0.89      0.85        96\n",
      "           2       0.79      0.84      0.81       106\n",
      "           3       0.98      0.83      0.90       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.1\n",
      "Accuracy :  90.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        92\n",
      "           1       0.86      0.91      0.88        96\n",
      "           2       0.85      0.89      0.87       106\n",
      "           3       0.98      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.1\n",
      "Accuracy :  91.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        92\n",
      "           1       0.87      0.90      0.88        96\n",
      "           2       0.89      0.90      0.89       106\n",
      "           3       0.97      0.92      0.94       106\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.1\n",
      "Accuracy :  92.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        92\n",
      "           1       0.89      0.88      0.88        96\n",
      "           2       0.90      0.92      0.91       106\n",
      "           3       0.98      0.92      0.95       106\n",
      "\n",
      "    accuracy                           0.92       400\n",
      "   macro avg       0.92      0.92      0.92       400\n",
      "weighted avg       0.92      0.92      0.92       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.1\n",
      "Accuracy :  90.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        92\n",
      "           1       0.88      0.89      0.88        96\n",
      "           2       0.85      0.89      0.87       106\n",
      "           3       0.95      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.1\n",
      "Accuracy :  90.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        92\n",
      "           1       0.88      0.89      0.88        96\n",
      "           2       0.83      0.90      0.86       106\n",
      "           3       0.96      0.89      0.92       106\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.91      0.90      0.90       400\n",
      "weighted avg       0.91      0.90      0.90       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.1\n",
      "Accuracy :  89.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        92\n",
      "           1       0.86      0.86      0.86        96\n",
      "           2       0.83      0.91      0.86       106\n",
      "           3       0.96      0.89      0.92       106\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.90      0.90      0.90       400\n",
      "weighted avg       0.90      0.90      0.90       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.1\n",
      "Accuracy :  89.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        92\n",
      "           1       0.86      0.85      0.86        96\n",
      "           2       0.82      0.91      0.86       106\n",
      "           3       0.96      0.89      0.92       106\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.90      0.89      0.89       400\n",
      "weighted avg       0.90      0.89      0.89       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.25\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93        92\n",
      "           1       0.78      0.82      0.80        96\n",
      "           2       0.77      0.84      0.81       106\n",
      "           3       0.99      0.85      0.91       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.25\n",
      "Accuracy :  88.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91        92\n",
      "           1       0.83      0.85      0.84        96\n",
      "           2       0.84      0.87      0.85       106\n",
      "           3       0.97      0.87      0.92       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.25\n",
      "Accuracy :  88.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93        92\n",
      "           1       0.81      0.86      0.84        96\n",
      "           2       0.83      0.86      0.85       106\n",
      "           3       0.98      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.89      0.89      0.89       400\n",
      "weighted avg       0.89      0.89      0.89       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.25\n",
      "Accuracy :  88.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93        92\n",
      "           1       0.82      0.84      0.83        96\n",
      "           2       0.82      0.87      0.84       106\n",
      "           3       0.97      0.90      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.89      0.88      0.88       400\n",
      "weighted avg       0.89      0.88      0.88       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.25\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93        92\n",
      "           1       0.81      0.82      0.82        96\n",
      "           2       0.81      0.86      0.83       106\n",
      "           3       0.95      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.25\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93        92\n",
      "           1       0.81      0.82      0.82        96\n",
      "           2       0.81      0.86      0.83       106\n",
      "           3       0.95      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.25\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93        92\n",
      "           1       0.81      0.82      0.82        96\n",
      "           2       0.81      0.86      0.83       106\n",
      "           3       0.95      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.25\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93        92\n",
      "           1       0.81      0.82      0.82        96\n",
      "           2       0.81      0.86      0.83       106\n",
      "           3       0.95      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.5\n",
      "Accuracy :  79.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        92\n",
      "           1       0.69      0.77      0.73        96\n",
      "           2       0.70      0.73      0.71       106\n",
      "           3       0.93      0.80      0.86       106\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.80      0.80      0.80       400\n",
      "weighted avg       0.80      0.80      0.80       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91        92\n",
      "           1       0.76      0.81      0.79        96\n",
      "           2       0.76      0.80      0.78       106\n",
      "           3       0.94      0.84      0.89       106\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.80      0.77        96\n",
      "           2       0.75      0.79      0.77       106\n",
      "           3       0.94      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.76      0.78      0.77       106\n",
      "           3       0.93      0.86      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.83      0.84       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 1\n",
      "Accuracy :  68.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82        92\n",
      "           1       0.55      0.66      0.60        96\n",
      "           2       0.56      0.60      0.58       106\n",
      "           3       0.86      0.72      0.78       106\n",
      "\n",
      "    accuracy                           0.69       400\n",
      "   macro avg       0.71      0.69      0.70       400\n",
      "weighted avg       0.71      0.69      0.69       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for g in [.1,.5,.10,.25,.50,1]:\n",
    "    for c in [1, 3, 5, 10, 40, 60, 80, 100]:\n",
    "        svc =  SVC(kernel=\"rbf\", C=c, gamma=g)\n",
    "        svc.fit(x_train, y_train)\n",
    "        svc_pred = svc.predict(x_test)\n",
    "        svc_acc_score = accuracy_score(y_test, svc_pred)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, svc_pred)\n",
    "        print(\"C=\", c)\n",
    "        print(\"Gamma=\", g)\n",
    "        print(\"Accuracy : \", accuracy * 100)\n",
    "\n",
    "        print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "current-johns",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:06:55.823452Z",
     "iopub.status.busy": "2021-05-24T17:06:55.823096Z",
     "iopub.status.idle": "2021-05-24T17:16:48.691890Z",
     "shell.execute_reply": "2021-05-24T17:16:48.691436Z",
     "shell.execute_reply.started": "2021-05-24T17:06:55.823424Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 1\n",
      "Accuracy :  93.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        92\n",
      "           1       0.90      0.92      0.91        96\n",
      "           2       0.88      0.91      0.89       106\n",
      "           3       0.98      0.92      0.95       106\n",
      "\n",
      "    accuracy                           0.93       400\n",
      "   macro avg       0.93      0.93      0.93       400\n",
      "weighted avg       0.93      0.93      0.93       400\n",
      "\n",
      "C= 3\n",
      "Accuracy :  94.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        92\n",
      "           1       0.92      0.94      0.93        96\n",
      "           2       0.91      0.92      0.91       106\n",
      "           3       0.98      0.94      0.96       106\n",
      "\n",
      "    accuracy                           0.94       400\n",
      "   macro avg       0.95      0.95      0.95       400\n",
      "weighted avg       0.95      0.94      0.95       400\n",
      "\n",
      "C= 5\n",
      "Accuracy :  95.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        92\n",
      "           1       0.95      0.93      0.94        96\n",
      "           2       0.92      0.94      0.93       106\n",
      "           3       0.98      0.95      0.97       106\n",
      "\n",
      "    accuracy                           0.95       400\n",
      "   macro avg       0.95      0.95      0.95       400\n",
      "weighted avg       0.95      0.95      0.95       400\n",
      "\n",
      "C= 10\n",
      "Accuracy :  95.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        92\n",
      "           1       0.94      0.94      0.94        96\n",
      "           2       0.93      0.93      0.93       106\n",
      "           3       0.99      0.96      0.98       106\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.96      0.96      0.96       400\n",
      "weighted avg       0.96      0.96      0.96       400\n",
      "\n",
      "C= 40\n",
      "Accuracy :  95.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        92\n",
      "           1       0.93      0.94      0.93        96\n",
      "           2       0.93      0.94      0.93       106\n",
      "           3       0.98      0.96      0.97       106\n",
      "\n",
      "    accuracy                           0.95       400\n",
      "   macro avg       0.95      0.95      0.95       400\n",
      "weighted avg       0.95      0.95      0.95       400\n",
      "\n",
      "C= 60\n",
      "Accuracy :  95.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        92\n",
      "           1       0.94      0.94      0.94        96\n",
      "           2       0.93      0.95      0.94       106\n",
      "           3       0.98      0.96      0.97       106\n",
      "\n",
      "    accuracy                           0.95       400\n",
      "   macro avg       0.96      0.95      0.96       400\n",
      "weighted avg       0.96      0.95      0.96       400\n",
      "\n",
      "C= 80\n",
      "Accuracy :  96.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        92\n",
      "           1       0.97      0.94      0.95        96\n",
      "           2       0.94      0.97      0.95       106\n",
      "           3       0.98      0.96      0.97       106\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.96      0.96      0.96       400\n",
      "weighted avg       0.96      0.96      0.96       400\n",
      "\n",
      "C= 100\n",
      "Accuracy :  96.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        92\n",
      "           1       0.96      0.95      0.95        96\n",
      "           2       0.95      0.96      0.96       106\n",
      "           3       0.98      0.97      0.98       106\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.96      0.97      0.96       400\n",
      "weighted avg       0.97      0.96      0.96       400\n",
      "\n",
      "C= 10000000000.0\n",
      "Accuracy :  95.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        92\n",
      "           1       0.92      0.97      0.94        96\n",
      "           2       0.94      0.93      0.94       106\n",
      "           3       0.98      0.95      0.97       106\n",
      "\n",
      "    accuracy                           0.95       400\n",
      "   macro avg       0.96      0.96      0.96       400\n",
      "weighted avg       0.96      0.95      0.96       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in [1, 3, 5, 10, 40, 60, 80, 100, 1e10]:\n",
    "    svc =  SVC(kernel=\"linear\", C=c)\n",
    "    svc.fit(x_train, y_train)\n",
    "    svc_pred = svc.predict(x_test)\n",
    "    svc_acc_score = accuracy_score(y_test, svc_pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, svc_pred)\n",
    "    print(\"C=\", c)\n",
    "    print(\"Accuracy : \", accuracy * 100)\n",
    "\n",
    "    print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "infinite-occasion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:03:29.056527Z",
     "iopub.status.busy": "2021-05-24T17:03:29.056073Z",
     "iopub.status.idle": "2021-05-24T17:03:33.218097Z",
     "shell.execute_reply": "2021-05-24T17:03:33.217444Z",
     "shell.execute_reply.started": "2021-05-24T17:03:29.056487Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 1\n",
      "Gamma= 0.1\n",
      "Accuracy :  80.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90        92\n",
      "           1       0.74      0.72      0.73        96\n",
      "           2       0.69      0.78      0.73       106\n",
      "           3       0.98      0.75      0.85       106\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.81      0.80      0.80       400\n",
      "weighted avg       0.81      0.80      0.80       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.1\n",
      "Accuracy :  85.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        92\n",
      "           1       0.81      0.82      0.82        96\n",
      "           2       0.76      0.85      0.80       106\n",
      "           3       0.98      0.80      0.88       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.85       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.1\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92        92\n",
      "           1       0.81      0.84      0.83        96\n",
      "           2       0.77      0.87      0.82       106\n",
      "           3       0.98      0.81      0.89       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91        92\n",
      "           1       0.81      0.85      0.83        96\n",
      "           2       0.83      0.87      0.85       106\n",
      "           3       0.98      0.86      0.91       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91        92\n",
      "           1       0.82      0.83      0.82        96\n",
      "           2       0.83      0.88      0.85       106\n",
      "           3       0.97      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91        92\n",
      "           1       0.80      0.81      0.80        96\n",
      "           2       0.81      0.86      0.83       106\n",
      "           3       0.96      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.87       400\n",
      "   macro avg       0.87      0.87      0.87       400\n",
      "weighted avg       0.87      0.87      0.87       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.1\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        92\n",
      "           1       0.78      0.81      0.80        96\n",
      "           2       0.78      0.86      0.82       106\n",
      "           3       0.97      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.1\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.98      0.88      0.93       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90        92\n",
      "           1       0.76      0.81      0.79        96\n",
      "           2       0.79      0.86      0.82       106\n",
      "           3       0.97      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.86      0.86      0.86       400\n",
      "weighted avg       0.86      0.86      0.86       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.1\n",
      "Accuracy :  80.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90        92\n",
      "           1       0.74      0.72      0.73        96\n",
      "           2       0.69      0.78      0.73       106\n",
      "           3       0.98      0.75      0.85       106\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.81      0.80      0.80       400\n",
      "weighted avg       0.81      0.80      0.80       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.1\n",
      "Accuracy :  85.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        92\n",
      "           1       0.81      0.82      0.82        96\n",
      "           2       0.76      0.85      0.80       106\n",
      "           3       0.98      0.80      0.88       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.85       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.1\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92        92\n",
      "           1       0.81      0.84      0.83        96\n",
      "           2       0.77      0.87      0.82       106\n",
      "           3       0.98      0.81      0.89       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91        92\n",
      "           1       0.81      0.85      0.83        96\n",
      "           2       0.83      0.87      0.85       106\n",
      "           3       0.98      0.86      0.91       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91        92\n",
      "           1       0.82      0.83      0.82        96\n",
      "           2       0.83      0.88      0.85       106\n",
      "           3       0.97      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91        92\n",
      "           1       0.80      0.81      0.80        96\n",
      "           2       0.81      0.86      0.83       106\n",
      "           3       0.96      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.87       400\n",
      "   macro avg       0.87      0.87      0.87       400\n",
      "weighted avg       0.87      0.87      0.87       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.1\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        92\n",
      "           1       0.78      0.81      0.80        96\n",
      "           2       0.78      0.86      0.82       106\n",
      "           3       0.97      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.1\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.98      0.88      0.93       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.25\n",
      "Accuracy :  88.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91        92\n",
      "           1       0.80      0.85      0.83        96\n",
      "           2       0.86      0.86      0.86       106\n",
      "           3       0.98      0.90      0.94       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.89      0.88      0.88       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.25\n",
      "Accuracy :  86.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91        92\n",
      "           1       0.81      0.79      0.80        96\n",
      "           2       0.80      0.88      0.84       106\n",
      "           3       0.97      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.87       400\n",
      "   macro avg       0.87      0.87      0.87       400\n",
      "weighted avg       0.87      0.87      0.87       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.25\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        92\n",
      "           1       0.78      0.81      0.80        96\n",
      "           2       0.78      0.86      0.82       106\n",
      "           3       0.97      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.25\n",
      "Accuracy :  85.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90        92\n",
      "           1       0.77      0.80      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.97      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.86      0.86      0.86       400\n",
      "weighted avg       0.86      0.86      0.86       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.25\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.25\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.25\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.25\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90        92\n",
      "           1       0.76      0.81      0.79        96\n",
      "           2       0.79      0.86      0.82       106\n",
      "           3       0.97      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.86      0.86      0.86       400\n",
      "weighted avg       0.86      0.86      0.86       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for g in [.1,.5,.10,.25,.50,1]:\n",
    "    for c in [1, 3, 5, 10, 40, 60, 80, 100]:\n",
    "        svc =  SVC(kernel=\"poly\", C=c, gamma=g)\n",
    "        svc.fit(x_train, y_train)\n",
    "        svc_pred = svc.predict(x_test)\n",
    "        svc_acc_score = accuracy_score(y_test, svc_pred)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, svc_pred)\n",
    "        print(\"C=\", c)\n",
    "        print(\"Gamma=\", g)\n",
    "        print(\"Accuracy : \", accuracy * 100)\n",
    "\n",
    "        print(classification_report(y_test,svc_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
