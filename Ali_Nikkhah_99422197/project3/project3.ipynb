{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "other-brooks",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:05:20.034738Z",
     "iopub.status.busy": "2021-04-06T12:05:20.034367Z",
     "iopub.status.idle": "2021-04-06T12:05:20.040994Z",
     "shell.execute_reply": "2021-04-06T12:05:20.040003Z",
     "shell.execute_reply.started": "2021-04-06T12:05:20.034704Z"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://sbu.ac.ir/documents/46019/275501/logo-dark.png\" alt=\"sbu\" class=\"center\">\n",
    "</center>\n",
    "\n",
    "\n",
    "# <center>Data Mining Course - Project #3</center>\n",
    "<center>\n",
    "    <b>Professors:</b>\n",
    "    <br>\n",
    "Dr. Farahani, Dr. Kheradpishe\n",
    "    <br><br><br>\n",
    "Ali Nikkhah - 99422197\n",
    "    <br><br>\n",
    "May 2021\n",
    "    <br><br>\n",
    "</center>\n",
    "\n",
    "\n",
    "# 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-thesaurus",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T15:25:58.312013Z",
     "iopub.status.busy": "2021-05-24T15:25:58.311050Z",
     "iopub.status.idle": "2021-05-24T15:25:58.325532Z",
     "shell.execute_reply": "2021-05-24T15:25:58.323908Z",
     "shell.execute_reply.started": "2021-05-24T15:25:58.311928Z"
    }
   },
   "source": [
    "<div style=\"direction:rtl; font-family:Vazir;font-size:16px;\">\n",
    " \n",
    "الگوریتم های SVM از مجموعه ای از توابع ریاضی که به عنوان کرنل تعریف می شوند، استفاده می کنند. وظیفه کرنل این است که داده ها را به عنوان ورودی گرفته و آن ها را به شکل مورد نیاز تبدیل کند. الگوریتم های مختلف SVM ، از انواع مختلف توابع کرنل استفاده می کنند. این توابع می توانند انواع متفاوتی داشته باشند. به عنوان مثال خطی ، غیرخطی ، چند جمله ای ، تابع پایه شعاعی (RBF) و سیگموئید.\n",
    "<br></br>\n",
    "توابع کرنل ، برای داده های ترتیبی ، نمودار ها ، متن ها ، تصاویر و همچنین بردار ها معرفی می شوند. پرکاربردترین نوع تابع کرنل، RBF است. زیرا دارای پاسخ محلی و متناهی در کل بازه محور x است.\n",
    " اما از لحاظ محاسباتی، محاسبه همه فیچر های اضافه مخصوصا در ترینینگ ست های بزرگ، هزینه زیادی دارد.\n",
    "<br></br>\n",
    "توابع کرنل ، ضرب داخلی بین دو نقطه در یک فضای ویژگی مناسب را برمی گردانند. بنابراین ، با هزینه محاسباتی کم، حتی در فضاهای با ابعاد بالا، مفهومی از شباهت را تعریف می کنند.\n",
    "<br></br>\n",
    "<b>کرنل چند جمله ای</b>\n",
    "<br></br>\n",
    "این کرنل در پردازش تصویر پرکاربرد است. معادله آن به صورت زیر است :\n",
    "<br>\n",
    "$$k(x_i,x_j)=(x_i\\cdot x_j+1)^d$$\n",
    "<br></br>\n",
    "که در آن d درجه چند جمله ای است.\n",
    "<br></br>\n",
    "<b>کرنل گاوسی</b>\n",
    "<br></br>\n",
    "این کرنل برای اهداف عمومی است. و هنگامی که هیچ دانش پیشینی در مورد داده ها وجود ندارد استفاده می شود. معادله آن به صورت زیر است :\n",
    "<br></br>\n",
    "$$k(x,y)=exp(-\\frac{\\left \\| x-y \\right \\|^{2}}{2\\sigma ^{2}})$$\n",
    "<br></br>\n",
    "<b>تابع پایه شعاعی گاوسی (RBF)</b>\n",
    "<br></br>\n",
    "این کرنل برای اهداف عمومی کاربرد دارد. و هنگامی که هیچ دانش پیشینی در مورد داده ها وجود نداشته باشد، مورد استفاده قرار می گیرد. معادله آن به صورت زیر است :\n",
    "<br></br>\n",
    "$$k(x_i,x_j)=exp(-\\gamma \\left \\| x_i - x_j \\right \\|^{2})$$\n",
    "<br></br>\n",
    "و برای\n",
    "<br>\n",
    "$$\\gamma > 0$$\n",
    "<br>\n",
    "گاهی اوقات با استفاده از پارامتر زیر استفاده می شود :\n",
    "<br></br>\n",
    "$$\\gamma = \\frac{1}{2\\sigma ^{2}}$$\n",
    "<br></br>\n",
    "<b>کرنل RBF لاپلاس</b>\n",
    "<br></br>\n",
    "این هم یک کرنل برای اهداف عمومی است. و هنگامی که هیچ دانش پیشینی در مورد داده ها وجود ندارد استفاده می شود. معادله آن به صورت زیر است :\n",
    "<br></br>\n",
    "$$k(x,y)=exp(-\\frac{\\left \\| x-y \\right \\|}{\\sigma })$$\n",
    "<br></br>\n",
    "<b>کرنل سیگموئید</b>\n",
    "<br></br>\n",
    "می توان این کرنل را در شبکه های عصبی مورد استفاده قرار داد. معادله مربوط به آن عبارت است از :\n",
    "<br></br>\n",
    "$$k(x,y)=\\tanh(\\alpha x^{T}y+c)$$\n",
    "<br></br>\n",
    "<b>کرنل spline خطی بصورت یک بعدی</b>\n",
    "<br></br>\n",
    "این کرنل، هنگام کار با بردارهای بزرگ داده پراکنده ، کاربرد زیادی دارد. این کرنل اغلب در دسته بندی متن مورد استفاده قرار می گیرد. کرنل spline همچنین در مسائل رگرسیون عملکرد خوبی دارد. معادله آن عبارت است از :\n",
    "<br></br>\n",
    "$$k(x,y)=1+xy+xy \\ min(x,y) -\\frac{x+y}{2} \\ min(x,y)^{2} + \\frac{1}{3} \\ min(x,y)^{3}$$\n",
    "<br></br>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-sacrifice",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "homeless-while",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:38:16.358692Z",
     "iopub.status.busy": "2021-06-04T18:38:16.358336Z",
     "iopub.status.idle": "2021-06-04T18:38:16.362012Z",
     "shell.execute_reply": "2021-06-04T18:38:16.361418Z",
     "shell.execute_reply.started": "2021-06-04T18:38:16.358661Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "equal-acquisition",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:38:16.900982Z",
     "iopub.status.busy": "2021-06-04T18:38:16.900722Z",
     "iopub.status.idle": "2021-06-04T18:38:16.929011Z",
     "shell.execute_reply": "2021-06-04T18:38:16.928346Z",
     "shell.execute_reply.started": "2021-06-04T18:38:16.900960Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 21)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1859</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1004</td>\n",
       "      <td>1654</td>\n",
       "      <td>1067</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1821</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>381</td>\n",
       "      <td>1018</td>\n",
       "      <td>3220</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1954</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.8</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>1149</td>\n",
       "      <td>700</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1445</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>836</td>\n",
       "      <td>1099</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1137</td>\n",
       "      <td>1224</td>\n",
       "      <td>513</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "5           1859     0          0.5         1   3       0          22    0.7   \n",
       "6           1821     0          1.7         0   4       1          10    0.8   \n",
       "7           1954     0          0.5         1   0       0          24    0.8   \n",
       "8           1445     1          0.5         0   0       0          53    0.7   \n",
       "9            509     1          0.6         1   2       1           9    0.1   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "5        164        1  ...       1004      1654  1067    17     1         10   \n",
       "6        139        8  ...        381      1018  3220    13     8         18   \n",
       "7        187        4  ...        512      1149   700    16     3          5   \n",
       "8        174        7  ...        386       836  1099    17     1         20   \n",
       "9         93        5  ...       1137      1224   513    19    10         12   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "5        1             0     0            1  \n",
       "6        1             0     1            3  \n",
       "7        1             1     1            0  \n",
       "8        1             0     0            0  \n",
       "9        1             0     0            0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_test = pd.read_csv(\"test.csv\")\n",
    "mobile_train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "display(mobile_train.shape)\n",
    "mobile_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "superb-tiffany",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:38:18.270557Z",
     "iopub.status.busy": "2021-06-04T18:38:18.270197Z",
     "iopub.status.idle": "2021-06-04T18:38:18.281414Z",
     "shell.execute_reply": "2021-06-04T18:38:18.280606Z",
     "shell.execute_reply.started": "2021-06-04T18:38:18.270526Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   int64  \n",
      " 1   blue           2000 non-null   int64  \n",
      " 2   clock_speed    2000 non-null   float64\n",
      " 3   dual_sim       2000 non-null   int64  \n",
      " 4   fc             2000 non-null   int64  \n",
      " 5   four_g         2000 non-null   int64  \n",
      " 6   int_memory     2000 non-null   int64  \n",
      " 7   m_dep          2000 non-null   float64\n",
      " 8   mobile_wt      2000 non-null   int64  \n",
      " 9   n_cores        2000 non-null   int64  \n",
      " 10  pc             2000 non-null   int64  \n",
      " 11  px_height      2000 non-null   int64  \n",
      " 12  px_width       2000 non-null   int64  \n",
      " 13  ram            2000 non-null   int64  \n",
      " 14  sc_h           2000 non-null   int64  \n",
      " 15  sc_w           2000 non-null   int64  \n",
      " 16  talk_time      2000 non-null   int64  \n",
      " 17  three_g        2000 non-null   int64  \n",
      " 18  touch_screen   2000 non-null   int64  \n",
      " 19  wifi           2000 non-null   int64  \n",
      " 20  price_range    2000 non-null   int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 328.2 KB\n"
     ]
    }
   ],
   "source": [
    "mobile_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "centered-integrity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:46:38.161057Z",
     "iopub.status.busy": "2021-06-04T18:46:38.160774Z",
     "iopub.status.idle": "2021-06-04T18:46:38.369809Z",
     "shell.execute_reply": "2021-06-04T18:46:38.368937Z",
     "shell.execute_reply.started": "2021-06-04T18:46:38.161034Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  83.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        92\n",
      "           1       0.77      0.78      0.77        96\n",
      "           2       0.74      0.81      0.77       106\n",
      "           3       0.97      0.83      0.89       106\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y = mobile_train[\"price_range\"].values\n",
    "x_data=mobile_train.drop([\"price_range\"],axis=1)\n",
    "x = (x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data))\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state=1)\n",
    "\n",
    "svc=SVC(random_state=1)\n",
    "svc.fit(x_train,y_train)\n",
    "svc_pred = svc.predict(x_test)\n",
    "svc_acc_score = accuracy_score(y_test, svc_pred)\n",
    "accuracy = accuracy_score(y_test, svc_pred)\n",
    "\n",
    "print(\"Accuracy : \", accuracy * 100)\n",
    "print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-torture",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T18:33:11.092579Z",
     "iopub.status.busy": "2021-04-09T18:33:11.092375Z",
     "iopub.status.idle": "2021-04-09T18:33:11.095592Z",
     "shell.execute_reply": "2021-04-09T18:33:11.094889Z",
     "shell.execute_reply.started": "2021-04-09T18:33:11.092562Z"
    }
   },
   "source": [
    "# 3 & 4.\n",
    "\n",
    "C > 0 : soft margin\n",
    "<br>\n",
    "more larger C => more harder margin\n",
    "\n",
    "gamma: Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dynamic-bridge",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T17:06:35.230710Z",
     "iopub.status.busy": "2021-06-04T17:06:35.230292Z",
     "iopub.status.idle": "2021-06-04T17:06:42.993799Z",
     "shell.execute_reply": "2021-06-04T17:06:42.993118Z",
     "shell.execute_reply.started": "2021-06-04T17:06:35.230675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 1\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        92\n",
      "           1       0.82      0.89      0.85        96\n",
      "           2       0.79      0.84      0.81       106\n",
      "           3       0.98      0.83      0.90       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.1\n",
      "Accuracy :  90.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        92\n",
      "           1       0.86      0.91      0.88        96\n",
      "           2       0.85      0.89      0.87       106\n",
      "           3       0.98      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.1\n",
      "Accuracy :  91.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        92\n",
      "           1       0.87      0.90      0.88        96\n",
      "           2       0.89      0.90      0.89       106\n",
      "           3       0.97      0.92      0.94       106\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.1\n",
      "Accuracy :  92.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        92\n",
      "           1       0.89      0.88      0.88        96\n",
      "           2       0.90      0.92      0.91       106\n",
      "           3       0.98      0.92      0.95       106\n",
      "\n",
      "    accuracy                           0.92       400\n",
      "   macro avg       0.92      0.92      0.92       400\n",
      "weighted avg       0.92      0.92      0.92       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.1\n",
      "Accuracy :  90.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        92\n",
      "           1       0.88      0.89      0.88        96\n",
      "           2       0.85      0.89      0.87       106\n",
      "           3       0.95      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.1\n",
      "Accuracy :  90.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        92\n",
      "           1       0.88      0.89      0.88        96\n",
      "           2       0.83      0.90      0.86       106\n",
      "           3       0.96      0.89      0.92       106\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.91      0.90      0.90       400\n",
      "weighted avg       0.91      0.90      0.90       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.1\n",
      "Accuracy :  89.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        92\n",
      "           1       0.86      0.86      0.86        96\n",
      "           2       0.83      0.91      0.86       106\n",
      "           3       0.96      0.89      0.92       106\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.90      0.90      0.90       400\n",
      "weighted avg       0.90      0.90      0.90       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.1\n",
      "Accuracy :  89.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        92\n",
      "           1       0.86      0.85      0.86        96\n",
      "           2       0.82      0.91      0.86       106\n",
      "           3       0.96      0.89      0.92       106\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.90      0.89      0.89       400\n",
      "weighted avg       0.90      0.89      0.89       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.5\n",
      "Accuracy :  79.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        92\n",
      "           1       0.69      0.77      0.73        96\n",
      "           2       0.70      0.73      0.71       106\n",
      "           3       0.93      0.80      0.86       106\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.80      0.80      0.80       400\n",
      "weighted avg       0.80      0.80      0.80       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91        92\n",
      "           1       0.76      0.81      0.79        96\n",
      "           2       0.76      0.80      0.78       106\n",
      "           3       0.94      0.84      0.89       106\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.80      0.77        96\n",
      "           2       0.75      0.79      0.77       106\n",
      "           3       0.94      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.76      0.78      0.77       106\n",
      "           3       0.93      0.86      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.83      0.84       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        92\n",
      "           1       0.82      0.89      0.85        96\n",
      "           2       0.79      0.84      0.81       106\n",
      "           3       0.98      0.83      0.90       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.1\n",
      "Accuracy :  90.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        92\n",
      "           1       0.86      0.91      0.88        96\n",
      "           2       0.85      0.89      0.87       106\n",
      "           3       0.98      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.1\n",
      "Accuracy :  91.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        92\n",
      "           1       0.87      0.90      0.88        96\n",
      "           2       0.89      0.90      0.89       106\n",
      "           3       0.97      0.92      0.94       106\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.1\n",
      "Accuracy :  92.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        92\n",
      "           1       0.89      0.88      0.88        96\n",
      "           2       0.90      0.92      0.91       106\n",
      "           3       0.98      0.92      0.95       106\n",
      "\n",
      "    accuracy                           0.92       400\n",
      "   macro avg       0.92      0.92      0.92       400\n",
      "weighted avg       0.92      0.92      0.92       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.1\n",
      "Accuracy :  90.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        92\n",
      "           1       0.88      0.89      0.88        96\n",
      "           2       0.85      0.89      0.87       106\n",
      "           3       0.95      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.1\n",
      "Accuracy :  90.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        92\n",
      "           1       0.88      0.89      0.88        96\n",
      "           2       0.83      0.90      0.86       106\n",
      "           3       0.96      0.89      0.92       106\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.91      0.90      0.90       400\n",
      "weighted avg       0.91      0.90      0.90       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.1\n",
      "Accuracy :  89.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        92\n",
      "           1       0.86      0.86      0.86        96\n",
      "           2       0.83      0.91      0.86       106\n",
      "           3       0.96      0.89      0.92       106\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.90      0.90      0.90       400\n",
      "weighted avg       0.90      0.90      0.90       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.1\n",
      "Accuracy :  89.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        92\n",
      "           1       0.86      0.85      0.86        96\n",
      "           2       0.82      0.91      0.86       106\n",
      "           3       0.96      0.89      0.92       106\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.90      0.89      0.89       400\n",
      "weighted avg       0.90      0.89      0.89       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.25\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93        92\n",
      "           1       0.78      0.82      0.80        96\n",
      "           2       0.77      0.84      0.81       106\n",
      "           3       0.99      0.85      0.91       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.25\n",
      "Accuracy :  88.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91        92\n",
      "           1       0.83      0.85      0.84        96\n",
      "           2       0.84      0.87      0.85       106\n",
      "           3       0.97      0.87      0.92       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.25\n",
      "Accuracy :  88.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93        92\n",
      "           1       0.81      0.86      0.84        96\n",
      "           2       0.83      0.86      0.85       106\n",
      "           3       0.98      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.89      0.89      0.89       400\n",
      "weighted avg       0.89      0.89      0.89       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.25\n",
      "Accuracy :  88.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93        92\n",
      "           1       0.82      0.84      0.83        96\n",
      "           2       0.82      0.87      0.84       106\n",
      "           3       0.97      0.90      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.89      0.88      0.88       400\n",
      "weighted avg       0.89      0.88      0.88       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.25\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93        92\n",
      "           1       0.81      0.82      0.82        96\n",
      "           2       0.81      0.86      0.83       106\n",
      "           3       0.95      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.25\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93        92\n",
      "           1       0.81      0.82      0.82        96\n",
      "           2       0.81      0.86      0.83       106\n",
      "           3       0.95      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.25\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93        92\n",
      "           1       0.81      0.82      0.82        96\n",
      "           2       0.81      0.86      0.83       106\n",
      "           3       0.95      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.25\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93        92\n",
      "           1       0.81      0.82      0.82        96\n",
      "           2       0.81      0.86      0.83       106\n",
      "           3       0.95      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.5\n",
      "Accuracy :  79.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        92\n",
      "           1       0.69      0.77      0.73        96\n",
      "           2       0.70      0.73      0.71       106\n",
      "           3       0.93      0.80      0.86       106\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.80      0.80      0.80       400\n",
      "weighted avg       0.80      0.80      0.80       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91        92\n",
      "           1       0.76      0.81      0.79        96\n",
      "           2       0.76      0.80      0.78       106\n",
      "           3       0.94      0.84      0.89       106\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.80      0.77        96\n",
      "           2       0.75      0.79      0.77       106\n",
      "           3       0.94      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.76      0.78      0.77       106\n",
      "           3       0.93      0.86      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.83      0.84       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.5\n",
      "Accuracy :  83.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        92\n",
      "           1       0.75      0.81      0.78        96\n",
      "           2       0.75      0.78      0.77       106\n",
      "           3       0.93      0.85      0.89       106\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.84       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 1\n",
      "Accuracy :  68.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82        92\n",
      "           1       0.55      0.66      0.60        96\n",
      "           2       0.56      0.60      0.58       106\n",
      "           3       0.86      0.72      0.78       106\n",
      "\n",
      "    accuracy                           0.69       400\n",
      "   macro avg       0.71      0.69      0.70       400\n",
      "weighted avg       0.71      0.69      0.69       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 1\n",
      "Accuracy :  72.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        92\n",
      "           1       0.61      0.69      0.64        96\n",
      "           2       0.61      0.66      0.64       106\n",
      "           3       0.87      0.75      0.80       106\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.74      0.72      0.73       400\n",
      "weighted avg       0.74      0.72      0.73       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for g in [.1,.5,.10,.25,.50,1]:\n",
    "    for c in [1, 3, 5, 10, 40, 60, 80, 100]:\n",
    "        svc =  SVC(kernel=\"rbf\", C=c, gamma=g)\n",
    "        svc.fit(x_train, y_train)\n",
    "        svc_pred = svc.predict(x_test)\n",
    "        svc_acc_score = accuracy_score(y_test, svc_pred)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, svc_pred)\n",
    "        print(\"C=\", c)\n",
    "        print(\"Gamma=\", g)\n",
    "        print(\"Accuracy : \", accuracy * 100)\n",
    "\n",
    "        print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "systematic-browse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T17:06:42.994824Z",
     "iopub.status.busy": "2021-06-04T17:06:42.994606Z",
     "iopub.status.idle": "2021-06-04T17:16:58.404386Z",
     "shell.execute_reply": "2021-06-04T17:16:58.403780Z",
     "shell.execute_reply.started": "2021-06-04T17:06:42.994807Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 1\n",
      "Accuracy :  93.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        92\n",
      "           1       0.90      0.92      0.91        96\n",
      "           2       0.88      0.91      0.89       106\n",
      "           3       0.98      0.92      0.95       106\n",
      "\n",
      "    accuracy                           0.93       400\n",
      "   macro avg       0.93      0.93      0.93       400\n",
      "weighted avg       0.93      0.93      0.93       400\n",
      "\n",
      "C= 3\n",
      "Accuracy :  94.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        92\n",
      "           1       0.92      0.94      0.93        96\n",
      "           2       0.91      0.92      0.91       106\n",
      "           3       0.98      0.94      0.96       106\n",
      "\n",
      "    accuracy                           0.94       400\n",
      "   macro avg       0.95      0.95      0.95       400\n",
      "weighted avg       0.95      0.94      0.95       400\n",
      "\n",
      "C= 5\n",
      "Accuracy :  95.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        92\n",
      "           1       0.95      0.93      0.94        96\n",
      "           2       0.92      0.94      0.93       106\n",
      "           3       0.98      0.95      0.97       106\n",
      "\n",
      "    accuracy                           0.95       400\n",
      "   macro avg       0.95      0.95      0.95       400\n",
      "weighted avg       0.95      0.95      0.95       400\n",
      "\n",
      "C= 10\n",
      "Accuracy :  95.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        92\n",
      "           1       0.94      0.94      0.94        96\n",
      "           2       0.93      0.93      0.93       106\n",
      "           3       0.99      0.96      0.98       106\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.96      0.96      0.96       400\n",
      "weighted avg       0.96      0.96      0.96       400\n",
      "\n",
      "C= 40\n",
      "Accuracy :  95.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        92\n",
      "           1       0.93      0.94      0.93        96\n",
      "           2       0.93      0.94      0.93       106\n",
      "           3       0.98      0.96      0.97       106\n",
      "\n",
      "    accuracy                           0.95       400\n",
      "   macro avg       0.95      0.95      0.95       400\n",
      "weighted avg       0.95      0.95      0.95       400\n",
      "\n",
      "C= 60\n",
      "Accuracy :  95.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        92\n",
      "           1       0.94      0.94      0.94        96\n",
      "           2       0.93      0.95      0.94       106\n",
      "           3       0.98      0.96      0.97       106\n",
      "\n",
      "    accuracy                           0.95       400\n",
      "   macro avg       0.96      0.95      0.96       400\n",
      "weighted avg       0.96      0.95      0.96       400\n",
      "\n",
      "C= 80\n",
      "Accuracy :  96.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        92\n",
      "           1       0.97      0.94      0.95        96\n",
      "           2       0.94      0.97      0.95       106\n",
      "           3       0.98      0.96      0.97       106\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.96      0.96      0.96       400\n",
      "weighted avg       0.96      0.96      0.96       400\n",
      "\n",
      "C= 100\n",
      "Accuracy :  96.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        92\n",
      "           1       0.96      0.95      0.95        96\n",
      "           2       0.95      0.96      0.96       106\n",
      "           3       0.98      0.97      0.98       106\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.96      0.97      0.96       400\n",
      "weighted avg       0.97      0.96      0.96       400\n",
      "\n",
      "C= 10000000000.0\n",
      "Accuracy :  95.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        92\n",
      "           1       0.92      0.97      0.94        96\n",
      "           2       0.94      0.93      0.94       106\n",
      "           3       0.98      0.95      0.97       106\n",
      "\n",
      "    accuracy                           0.95       400\n",
      "   macro avg       0.96      0.96      0.96       400\n",
      "weighted avg       0.96      0.95      0.96       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in [1, 3, 5, 10, 40, 60, 80, 100, 1e10]:\n",
    "    svc =  SVC(kernel=\"linear\", C=c)\n",
    "    svc.fit(x_train, y_train)\n",
    "    svc_pred = svc.predict(x_test)\n",
    "    svc_acc_score = accuracy_score(y_test, svc_pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, svc_pred)\n",
    "    print(\"C=\", c)\n",
    "    print(\"Accuracy : \", accuracy * 100)\n",
    "\n",
    "    print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prime-physiology",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T17:16:58.406565Z",
     "iopub.status.busy": "2021-06-04T17:16:58.406202Z",
     "iopub.status.idle": "2021-06-04T17:17:02.409357Z",
     "shell.execute_reply": "2021-06-04T17:17:02.408580Z",
     "shell.execute_reply.started": "2021-06-04T17:16:58.406537Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 1\n",
      "Gamma= 0.1\n",
      "Accuracy :  80.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90        92\n",
      "           1       0.74      0.72      0.73        96\n",
      "           2       0.69      0.78      0.73       106\n",
      "           3       0.98      0.75      0.85       106\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.81      0.80      0.80       400\n",
      "weighted avg       0.81      0.80      0.80       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.1\n",
      "Accuracy :  85.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        92\n",
      "           1       0.81      0.82      0.82        96\n",
      "           2       0.76      0.85      0.80       106\n",
      "           3       0.98      0.80      0.88       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.85       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.1\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92        92\n",
      "           1       0.81      0.84      0.83        96\n",
      "           2       0.77      0.87      0.82       106\n",
      "           3       0.98      0.81      0.89       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91        92\n",
      "           1       0.81      0.85      0.83        96\n",
      "           2       0.83      0.87      0.85       106\n",
      "           3       0.98      0.86      0.91       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91        92\n",
      "           1       0.82      0.83      0.82        96\n",
      "           2       0.83      0.88      0.85       106\n",
      "           3       0.97      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91        92\n",
      "           1       0.80      0.81      0.80        96\n",
      "           2       0.81      0.86      0.83       106\n",
      "           3       0.96      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.87       400\n",
      "   macro avg       0.87      0.87      0.87       400\n",
      "weighted avg       0.87      0.87      0.87       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.1\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        92\n",
      "           1       0.78      0.81      0.80        96\n",
      "           2       0.78      0.86      0.82       106\n",
      "           3       0.97      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.1\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.98      0.88      0.93       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90        92\n",
      "           1       0.76      0.81      0.79        96\n",
      "           2       0.79      0.86      0.82       106\n",
      "           3       0.97      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.86      0.86      0.86       400\n",
      "weighted avg       0.86      0.86      0.86       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.1\n",
      "Accuracy :  80.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90        92\n",
      "           1       0.74      0.72      0.73        96\n",
      "           2       0.69      0.78      0.73       106\n",
      "           3       0.98      0.75      0.85       106\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.81      0.80      0.80       400\n",
      "weighted avg       0.81      0.80      0.80       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.1\n",
      "Accuracy :  85.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        92\n",
      "           1       0.81      0.82      0.82        96\n",
      "           2       0.76      0.85      0.80       106\n",
      "           3       0.98      0.80      0.88       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.85       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.1\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92        92\n",
      "           1       0.81      0.84      0.83        96\n",
      "           2       0.77      0.87      0.82       106\n",
      "           3       0.98      0.81      0.89       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91        92\n",
      "           1       0.81      0.85      0.83        96\n",
      "           2       0.83      0.87      0.85       106\n",
      "           3       0.98      0.86      0.91       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91        92\n",
      "           1       0.82      0.83      0.82        96\n",
      "           2       0.83      0.88      0.85       106\n",
      "           3       0.97      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.1\n",
      "Accuracy :  87.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91        92\n",
      "           1       0.80      0.81      0.80        96\n",
      "           2       0.81      0.86      0.83       106\n",
      "           3       0.96      0.91      0.93       106\n",
      "\n",
      "    accuracy                           0.87       400\n",
      "   macro avg       0.87      0.87      0.87       400\n",
      "weighted avg       0.87      0.87      0.87       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.1\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        92\n",
      "           1       0.78      0.81      0.80        96\n",
      "           2       0.78      0.86      0.82       106\n",
      "           3       0.97      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.1\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.98      0.88      0.93       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.25\n",
      "Accuracy :  88.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91        92\n",
      "           1       0.80      0.85      0.83        96\n",
      "           2       0.86      0.86      0.86       106\n",
      "           3       0.98      0.90      0.94       106\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.89      0.88      0.88       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.25\n",
      "Accuracy :  86.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91        92\n",
      "           1       0.81      0.79      0.80        96\n",
      "           2       0.80      0.88      0.84       106\n",
      "           3       0.97      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.87       400\n",
      "   macro avg       0.87      0.87      0.87       400\n",
      "weighted avg       0.87      0.87      0.87       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.25\n",
      "Accuracy :  86.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        92\n",
      "           1       0.78      0.81      0.80        96\n",
      "           2       0.78      0.86      0.82       106\n",
      "           3       0.97      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.87      0.86      0.86       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.25\n",
      "Accuracy :  85.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90        92\n",
      "           1       0.77      0.80      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.97      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.86      0.86      0.86       400\n",
      "weighted avg       0.86      0.86      0.86       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.25\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.25\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.25\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.25\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90        92\n",
      "           1       0.76      0.81      0.79        96\n",
      "           2       0.79      0.86      0.82       106\n",
      "           3       0.97      0.89      0.93       106\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.86      0.86      0.86       400\n",
      "weighted avg       0.86      0.86      0.86       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 0.5\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 1\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 3\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 5\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 10\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 40\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 60\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 80\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n",
      "C= 100\n",
      "Gamma= 1\n",
      "Accuracy :  85.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        92\n",
      "           1       0.77      0.81      0.79        96\n",
      "           2       0.79      0.87      0.83       106\n",
      "           3       0.96      0.88      0.92       106\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.86      0.85      0.86       400\n",
      "weighted avg       0.86      0.85      0.86       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for g in [.1,.5,.10,.25,.50,1]:\n",
    "    for c in [1, 3, 5, 10, 40, 60, 80, 100]:\n",
    "        svc =  SVC(kernel=\"poly\", C=c, gamma=g)\n",
    "        svc.fit(x_train, y_train)\n",
    "        svc_pred = svc.predict(x_test)\n",
    "        svc_acc_score = accuracy_score(y_test, svc_pred)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, svc_pred)\n",
    "        print(\"C=\", c)\n",
    "        print(\"Gamma=\", g)\n",
    "        print(\"Accuracy : \", accuracy * 100)\n",
    "\n",
    "        print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-regulation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T16:57:30.537628Z",
     "iopub.status.busy": "2021-06-04T16:57:30.537293Z",
     "iopub.status.idle": "2021-06-04T16:57:30.540683Z",
     "shell.execute_reply": "2021-06-04T16:57:30.540066Z",
     "shell.execute_reply.started": "2021-06-04T16:57:30.537601Z"
    }
   },
   "source": [
    "# 5.\n",
    "   ### A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "danish-fiber",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:38:30.357225Z",
     "iopub.status.busy": "2021-06-04T18:38:30.356941Z",
     "iopub.status.idle": "2021-06-04T18:38:30.377028Z",
     "shell.execute_reply": "2021-06-04T18:38:30.376558Z",
     "shell.execute_reply.started": "2021-06-04T18:38:30.357191Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1004</td>\n",
       "      <td>1654</td>\n",
       "      <td>1067</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>381</td>\n",
       "      <td>1018</td>\n",
       "      <td>3220</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.8</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>1149</td>\n",
       "      <td>700</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>836</td>\n",
       "      <td>1099</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1137</td>\n",
       "      <td>1224</td>\n",
       "      <td>513</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0             0     0          2.2         0   1       0           7    0.6   \n",
       "1             1     1          0.5         1   0       1          53    0.7   \n",
       "2             0     1          0.5         1   2       1          41    0.9   \n",
       "3             0     1          2.5         0   0       0          10    0.8   \n",
       "4             2     1          1.2         0  13       1          44    0.6   \n",
       "5             2     0          0.5         1   3       0          22    0.7   \n",
       "6             2     0          1.7         0   4       1          10    0.8   \n",
       "7             2     0          0.5         1   0       0          24    0.8   \n",
       "8             1     1          0.5         0   0       0          53    0.7   \n",
       "9             0     1          0.6         1   2       1           9    0.1   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "5        164        1  ...       1004      1654  1067    17     1         10   \n",
       "6        139        8  ...        381      1018  3220    13     8         18   \n",
       "7        187        4  ...        512      1149   700    16     3          5   \n",
       "8        174        7  ...        386       836  1099    17     1         20   \n",
       "9         93        5  ...       1137      1224   513    19    10         12   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "5        1             0     0            1  \n",
       "6        1             0     1            3  \n",
       "7        1             1     1            0  \n",
       "8        1             0     0            0  \n",
       "9        1             0     0            0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum = mobile_train['battery_power'].min()\n",
    "maximum = mobile_train['battery_power'].max()\n",
    "\n",
    "mobile_train_binned = mobile_train.copy()\n",
    "bins = np.linspace(minimum, maximum, 4)\n",
    "labels = [0, 1, 2]\n",
    "mobile_train_binned['battery_power'] = pd.cut(mobile_train['battery_power'], bins=bins, labels=labels, include_lowest=True)\n",
    "mobile_train_binned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-encounter",
   "metadata": {},
   "source": [
    "### B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-strand",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T17:47:13.153805Z",
     "iopub.status.busy": "2021-06-04T17:47:13.153563Z",
     "iopub.status.idle": "2021-06-04T17:47:13.159193Z",
     "shell.execute_reply": "2021-06-04T17:47:13.158168Z",
     "shell.execute_reply.started": "2021-06-04T17:47:13.153787Z"
    }
   },
   "source": [
    "One-hot encoding transforms categorical features to a format that works better with classification and regression algorithms. It's very useful in methods where multiple types of data representation is necessary.\n",
    "\n",
    "For example, some vectors may be optimal for regression (approximating functions based on former return values), and some may be optimal for classification (categorization into fixed sets/classes, typically binary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "muslim-briefing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T17:45:14.788656Z",
     "iopub.status.busy": "2021-06-04T17:45:14.788185Z",
     "iopub.status.idle": "2021-06-04T17:45:14.801951Z",
     "shell.execute_reply": "2021-06-04T17:45:14.801236Z",
     "shell.execute_reply.started": "2021-06-04T17:45:14.788617Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Normalizing the data\n",
    "sc = StandardScaler()\n",
    "X=mobile_train.iloc[:,:-1].values\n",
    "y=mobile_train.iloc[:,20:21].values\n",
    "X = sc.fit_transform(X)\n",
    "# One Hot Encoder\n",
    "ohe=OneHotEncoder()\n",
    "y=ohe.fit_transform(y).toarray()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-economy",
   "metadata": {},
   "source": [
    "### C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "compliant-holiday",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:27:12.749122Z",
     "iopub.status.busy": "2021-06-04T18:27:12.748818Z",
     "iopub.status.idle": "2021-06-04T18:27:13.015559Z",
     "shell.execute_reply": "2021-06-04T18:27:13.014844Z",
     "shell.execute_reply.started": "2021-06-04T18:27:12.749096Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f0b8e407c88>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Check Distribution of price_range\n",
    "sns.displot(mobile_train['price_range'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-colonial",
   "metadata": {},
   "source": [
    "price_range is normally distributed! So no need to transformation.\n",
    "\n",
    "The log transform is a specific example of a family of transformations known as power transforms. In statistical terms, these are variance-stabilizing transformations.\n",
    "We can apply a power transform directly by calculating the log or square root of the variable, although this may or may not be the best power transform for a given variable.\n",
    "\n",
    "There are two popular approaches for such automatic power transforms; they are:\n",
    "\n",
    "    Box-Cox Transform\n",
    "    Yeo-Johnson Transform\n",
    "\n",
    "We can use this methods when data is skewed.\n",
    "\n",
    "but there is no skewed feature: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "active-basin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:27:15.310604Z",
     "iopub.status.busy": "2021-06-04T18:27:15.310246Z",
     "iopub.status.idle": "2021-06-04T18:27:15.326107Z",
     "shell.execute_reply": "2021-06-04T18:27:15.325297Z",
     "shell.execute_reply.started": "2021-06-04T18:27:15.310572Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fc</th>\n",
       "      <td>1.019811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>px_height</th>\n",
       "      <td>0.666271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_w</th>\n",
       "      <td>0.633787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clock_speed</th>\n",
       "      <td>0.178084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_dep</th>\n",
       "      <td>0.089082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_memory</th>\n",
       "      <td>0.057889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>battery_power</th>\n",
       "      <td>0.031898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>0.020016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc</th>\n",
       "      <td>0.017306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>px_width</th>\n",
       "      <td>0.014787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk_time</th>\n",
       "      <td>0.009512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram</th>\n",
       "      <td>0.006628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile_wt</th>\n",
       "      <td>0.006558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_cores</th>\n",
       "      <td>0.003628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_range</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>touch_screen</th>\n",
       "      <td>-0.012009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wifi</th>\n",
       "      <td>-0.028024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dual_sim</th>\n",
       "      <td>-0.038035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four_g</th>\n",
       "      <td>-0.086144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_h</th>\n",
       "      <td>-0.098884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three_g</th>\n",
       "      <td>-1.228142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Skew\n",
       "fc             1.019811\n",
       "px_height      0.666271\n",
       "sc_w           0.633787\n",
       "clock_speed    0.178084\n",
       "m_dep          0.089082\n",
       "int_memory     0.057889\n",
       "battery_power  0.031898\n",
       "blue           0.020016\n",
       "pc             0.017306\n",
       "px_width       0.014787\n",
       "talk_time      0.009512\n",
       "ram            0.006628\n",
       "mobile_wt      0.006558\n",
       "n_cores        0.003628\n",
       "price_range    0.000000\n",
       "touch_screen  -0.012009\n",
       "wifi          -0.028024\n",
       "dual_sim      -0.038035\n",
       "four_g        -0.086144\n",
       "sc_h          -0.098884\n",
       "three_g       -1.228142"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skew_features = mobile_train[num_feets].skew().sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew': skew_features})\n",
    "skewness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-antique",
   "metadata": {},
   "source": [
    "### C.\n",
    "\n",
    "sc_h: Screen Height of mobile in cm\n",
    "\n",
    "sc_w: Screen Width of mobile in cm\n",
    "\n",
    "m_dep: Mobile Depth in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "narrow-penalty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:48:30.376273Z",
     "iopub.status.busy": "2021-06-04T18:48:30.376031Z",
     "iopub.status.idle": "2021-06-04T18:48:30.382616Z",
     "shell.execute_reply": "2021-06-04T18:48:30.381632Z",
     "shell.execute_reply.started": "2021-06-04T18:48:30.376254Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        63\n",
       "1        51\n",
       "2        22\n",
       "3       128\n",
       "4        16\n",
       "       ... \n",
       "1995     52\n",
       "1996    110\n",
       "1997      9\n",
       "1998    180\n",
       "1999     76\n",
       "Name: aria, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_train_extended = mobile_train.copy()\n",
    "\n",
    "mobile_train_extended['aria'] = mobile_train['sc_h'] * mobile_train['sc_w']\n",
    "mobile_train_extended['aria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "derived-masters",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:48:31.024982Z",
     "iopub.status.busy": "2021-06-04T18:48:31.024097Z",
     "iopub.status.idle": "2021-06-04T18:48:31.052559Z",
     "shell.execute_reply": "2021-06-04T18:48:31.049887Z",
     "shell.execute_reply.started": "2021-06-04T18:48:31.024902Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        37.8\n",
       "1        35.7\n",
       "2        19.8\n",
       "3       102.4\n",
       "4         9.6\n",
       "        ...  \n",
       "1995     41.6\n",
       "1996     22.0\n",
       "1997      6.3\n",
       "1998     18.0\n",
       "1999     68.4\n",
       "Name: volume, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_train_extended['volume'] = mobile_train['sc_h'] * mobile_train['sc_w'] * mobile_train['m_dep']\n",
    "mobile_train_extended['volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "reasonable-relationship",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:48:32.687411Z",
     "iopub.status.busy": "2021-06-04T18:48:32.687188Z",
     "iopub.status.idle": "2021-06-04T18:48:32.721717Z",
     "shell.execute_reply": "2021-06-04T18:48:32.721176Z",
     "shell.execute_reply.started": "2021-06-04T18:48:32.687393Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "      <th>aria</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>37.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>35.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>102.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>41.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0               842     0          2.2         0   1       0           7   \n",
       "1              1021     1          0.5         1   0       1          53   \n",
       "2               563     1          0.5         1   2       1          41   \n",
       "3               615     1          2.5         0   0       0          10   \n",
       "4              1821     1          1.2         0  13       1          44   \n",
       "...             ...   ...          ...       ...  ..     ...         ...   \n",
       "1995            794     1          0.5         1   0       1           2   \n",
       "1996           1965     1          2.6         1   0       0          39   \n",
       "1997           1911     0          0.9         1   1       1          36   \n",
       "1998           1512     0          0.9         0   4       1          46   \n",
       "1999            510     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  ...   ram  sc_h  sc_w  talk_time  three_g  \\\n",
       "0       0.6        188        2  ...  2549     9     7         19        0   \n",
       "1       0.7        136        3  ...  2631    17     3          7        1   \n",
       "2       0.9        145        5  ...  2603    11     2          9        1   \n",
       "3       0.8        131        6  ...  2769    16     8         11        1   \n",
       "4       0.6        141        2  ...  1411     8     2         15        1   \n",
       "...     ...        ...      ...  ...   ...   ...   ...        ...      ...   \n",
       "1995    0.8        106        6  ...   668    13     4         19        1   \n",
       "1996    0.2        187        4  ...  2032    11    10         16        1   \n",
       "1997    0.7        108        8  ...  3057     9     1          5        1   \n",
       "1998    0.1        145        5  ...   869    18    10         19        1   \n",
       "1999    0.9        168        6  ...  3919    19     4          2        1   \n",
       "\n",
       "      touch_screen  wifi  price_range  aria  volume  \n",
       "0                0     1            1    63    37.8  \n",
       "1                1     0            2    51    35.7  \n",
       "2                1     0            2    22    19.8  \n",
       "3                0     0            2   128   102.4  \n",
       "4                1     0            1    16     9.6  \n",
       "...            ...   ...          ...   ...     ...  \n",
       "1995             1     0            0    52    41.6  \n",
       "1996             1     1            2   110    22.0  \n",
       "1997             1     0            3     9     6.3  \n",
       "1998             1     1            0   180    18.0  \n",
       "1999             1     1            3    76    68.4  \n",
       "\n",
       "[2000 rows x 23 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_train_extended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-catalog",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:34:28.262736Z",
     "iopub.status.busy": "2021-06-04T18:34:28.262453Z",
     "iopub.status.idle": "2021-06-04T18:34:28.265511Z",
     "shell.execute_reply": "2021-06-04T18:34:28.264810Z",
     "shell.execute_reply.started": "2021-06-04T18:34:28.262713Z"
    }
   },
   "source": [
    "# 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "electronic-punch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:48:35.508552Z",
     "iopub.status.busy": "2021-06-04T18:48:35.508094Z",
     "iopub.status.idle": "2021-06-04T18:48:35.598763Z",
     "shell.execute_reply": "2021-06-04T18:48:35.597846Z",
     "shell.execute_reply.started": "2021-06-04T18:48:35.508512Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binning method on 'battery power'\n",
      "\n",
      "Accuracy :  76.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86        92\n",
      "           1       0.67      0.75      0.71        96\n",
      "           2       0.68      0.67      0.67       106\n",
      "           3       0.86      0.80      0.83       106\n",
      "\n",
      "    accuracy                           0.76       400\n",
      "   macro avg       0.77      0.76      0.77       400\n",
      "weighted avg       0.77      0.76      0.76       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = mobile_train_binned[\"price_range\"].values\n",
    "x_data=mobile_train_binned.drop([\"price_range\"],axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data,y,test_size = 0.2,random_state=1)\n",
    "\n",
    "svc=SVC(random_state=1)\n",
    "svc.fit(x_train,y_train)\n",
    "svc_pred = svc.predict(x_test)\n",
    "svc_acc_score = accuracy_score(y_test, svc_pred)\n",
    "accuracy = accuracy_score(y_test, svc_pred)\n",
    "\n",
    "print(\"binning method on 'battery power'\\n\")\n",
    "print(\"Accuracy : \", accuracy * 100)\n",
    "print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "killing-bottle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:48:36.733318Z",
     "iopub.status.busy": "2021-06-04T18:48:36.732556Z",
     "iopub.status.idle": "2021-06-04T18:48:36.834761Z",
     "shell.execute_reply": "2021-06-04T18:48:36.834102Z",
     "shell.execute_reply.started": "2021-06-04T18:48:36.733252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC on extended dataset\n",
      "\n",
      "Accuracy :  94.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        92\n",
      "           1       0.92      0.95      0.93        96\n",
      "           2       0.92      0.91      0.91       106\n",
      "           3       0.97      0.94      0.96       106\n",
      "\n",
      "    accuracy                           0.94       400\n",
      "   macro avg       0.95      0.95      0.95       400\n",
      "weighted avg       0.95      0.94      0.94       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = mobile_train_extended[\"price_range\"].values\n",
    "x_data=mobile_train_extended.drop([\"price_range\"],axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data,y,test_size = 0.2,random_state=1)\n",
    "\n",
    "svc=SVC(random_state=1)\n",
    "svc.fit(x_train,y_train)\n",
    "svc_pred = svc.predict(x_test)\n",
    "svc_acc_score = accuracy_score(y_test, svc_pred)\n",
    "accuracy = accuracy_score(y_test, svc_pred)\n",
    "\n",
    "print(\"SVC on extended dataset\\n\")\n",
    "print(\"Accuracy : \", accuracy * 100)\n",
    "print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ultimate-anniversary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:48:38.663623Z",
     "iopub.status.busy": "2021-06-04T18:48:38.663308Z",
     "iopub.status.idle": "2021-06-04T18:48:38.691540Z",
     "shell.execute_reply": "2021-06-04T18:48:38.690732Z",
     "shell.execute_reply.started": "2021-06-04T18:48:38.663596Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "      <th>aria</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>37.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>35.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>102.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>41.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0                0     0          2.2         0   1       0           7   \n",
       "1                1     1          0.5         1   0       1          53   \n",
       "2                0     1          0.5         1   2       1          41   \n",
       "3                0     1          2.5         0   0       0          10   \n",
       "4                2     1          1.2         0  13       1          44   \n",
       "...            ...   ...          ...       ...  ..     ...         ...   \n",
       "1995             0     1          0.5         1   0       1           2   \n",
       "1996             2     1          2.6         1   0       0          39   \n",
       "1997             2     0          0.9         1   1       1          36   \n",
       "1998             2     0          0.9         0   4       1          46   \n",
       "1999             0     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  ...   ram  sc_h  sc_w  talk_time  three_g  \\\n",
       "0       0.6        188        2  ...  2549     9     7         19        0   \n",
       "1       0.7        136        3  ...  2631    17     3          7        1   \n",
       "2       0.9        145        5  ...  2603    11     2          9        1   \n",
       "3       0.8        131        6  ...  2769    16     8         11        1   \n",
       "4       0.6        141        2  ...  1411     8     2         15        1   \n",
       "...     ...        ...      ...  ...   ...   ...   ...        ...      ...   \n",
       "1995    0.8        106        6  ...   668    13     4         19        1   \n",
       "1996    0.2        187        4  ...  2032    11    10         16        1   \n",
       "1997    0.7        108        8  ...  3057     9     1          5        1   \n",
       "1998    0.1        145        5  ...   869    18    10         19        1   \n",
       "1999    0.9        168        6  ...  3919    19     4          2        1   \n",
       "\n",
       "      touch_screen  wifi  price_range  aria  volume  \n",
       "0                0     1            1    63    37.8  \n",
       "1                1     0            2    51    35.7  \n",
       "2                1     0            2    22    19.8  \n",
       "3                0     0            2   128   102.4  \n",
       "4                1     0            1    16     9.6  \n",
       "...            ...   ...          ...   ...     ...  \n",
       "1995             1     0            0    52    41.6  \n",
       "1996             1     1            2   110    22.0  \n",
       "1997             1     0            3     9     6.3  \n",
       "1998             1     1            0   180    18.0  \n",
       "1999             1     1            3    76    68.4  \n",
       "\n",
       "[2000 rows x 23 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_train_combined = mobile_train_extended\n",
    "mobile_train_combined['battery_power'] = mobile_train_binned['battery_power']\n",
    "mobile_train_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "qualified-count",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T18:48:40.571493Z",
     "iopub.status.busy": "2021-06-04T18:48:40.571137Z",
     "iopub.status.idle": "2021-06-04T18:48:40.748929Z",
     "shell.execute_reply": "2021-06-04T18:48:40.747745Z",
     "shell.execute_reply.started": "2021-06-04T18:48:40.571463Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC on combined dataset\n",
      "\n",
      "Accuracy :  83.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        92\n",
      "           1       0.77      0.78      0.77        96\n",
      "           2       0.74      0.81      0.77       106\n",
      "           3       0.97      0.83      0.89       106\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y = mobile_train_combined[\"price_range\"].values\n",
    "x_data=mobile_train_combined.drop([\"price_range\"],axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state=1)\n",
    "\n",
    "svc=SVC(random_state=1)\n",
    "svc.fit(x_train,y_train)\n",
    "svc_pred = svc.predict(x_test)\n",
    "svc_acc_score = accuracy_score(y_test, svc_pred)\n",
    "accuracy = accuracy_score(y_test, svc_pred)\n",
    "\n",
    "print(\"SVC on combined dataset\\n\")\n",
    "print(\"Accuracy : \", accuracy * 100)\n",
    "print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-guide",
   "metadata": {},
   "source": [
    "So, Best __Accuracy is %94.5__ for extended dataset.\n",
    "\n",
    "Best Regards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
